{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295ca9e5-da88-4149-9e14-887b7c9ffb28",
   "metadata": {},
   "source": [
    "# Image Classification with Vision Transformers\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- comments: true\n",
    "- author: Shohjahon Nishonov\n",
    "- categories: [Deep Learning, Computer Vision, Transformers]\n",
    "- image: images/vit.jpeg\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acb7ce-2c4e-4555-a055-5fc9b22aceaf",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "It is a fact that Convolutional Neural Networks(CNN) have been dominant in Copmuter Vision tasks. However, [ViT - AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://arxiv.org/abs/2010.11929 \"\") paper showed great results compared to SotA models. Here, we will dive deep enough to understand the Transformers architecure and apply the model to some practical tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9899c-375e-454e-84da-e11d8e9f1a4d",
   "metadata": {},
   "source": [
    "{cite}'voita2020nlpCourse'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c3b01-bd60-4a7e-8f51-dc71d18f4a1f",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Framework Basics\n",
    "Encoder-decoder framework is used for sequence-to-sequence tasks, for example, machine translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479203ca-6af9-4849-80e7-e1b4c5ec2dd9",
   "metadata": {},
   "source": [
    "![alt text](../images/encoder-decoder.jpg \"Encoder-Decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f3504-475d-4506-afc3-1a2e63c4b228",
   "metadata": {},
   "source": [
    "The simplest model consists of two RNNs: one for the encoder and another for the decoder. Encoder reads the source sentence and produces a context vector where all the information about the source sentence is encoded. Then, decoder reads the context vector and generates output sentence based on this vector. The problem with such a model is that encoder tries to compress the whole source sentence into a fixed size vector. This can be hard, especially with long text inputs. It cannot put all information into a single vector without loosing some meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703564aa-f6b4-49a9-99f1-4774701dbe91",
   "metadata": {},
   "source": [
    "> Note: Imagine explaining a topic with few words. Only hope is the other person understands it as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8a8a0-4a63-4293-80ee-ffa021159a99",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672b6ab-010d-4ffb-90b3-21e239e03fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
